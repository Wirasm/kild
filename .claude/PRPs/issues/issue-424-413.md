# Investigation: Log errors before .ok() discards + Daemon PTY cleanup on destroy/complete

**Issues**: #424 (https://github.com/Wirasm/kild/issues/424) + #413 (https://github.com/Wirasm/kild/issues/413)
**Type**: BUG
**Investigated**: 2026-02-16T12:00:00Z

### Assessment

| Metric     | Value  | Reasoning                                                                                         |
| ---------- | ------ | ------------------------------------------------------------------------------------------------- |
| Severity   | MEDIUM | Silent failures degrade debuggability; orphaned PTYs waste resources but don't cause data loss    |
| Complexity | MEDIUM | 4 files to update, one new daemon client function, well-understood patterns to follow             |
| Confidence | HIGH   | All affected code paths traced with line references, clear patterns to mirror from existing code   |

---

## Problem Statement

Two related issues in KILD's cleanup infrastructure:

1. **#424**: Several `if let Ok(...)` patterns in `cleanup/operations.rs` silently skip items when git2 operations fail, violating the "No Silent Failures" project principle. The cleanup detection functions (`detect_orphaned_branches`, `detect_orphaned_worktrees`) lose error details that are needed for debugging.

2. **#413**: `kild destroy` and `kild complete` only clean up daemon sessions tracked in `session.agents()`. UI-created daemon sessions (pattern `{session_id}_ui_shell_N`) are not tracked in the session file and leak as orphaned PTYs in the daemon.

---

## Analysis

### Issue #424: Silent error discards

**Note**: Many `.ok()` patterns in `destroy.rs` referenced in the original issue have **already been fixed** in the current code (e.g., shim cleanup, child PTY destruction). The remaining gaps are in `cleanup/operations.rs`.

#### Remaining gaps in `cleanup/operations.rs`

**`detect_orphaned_branches()` — lines 47-55**: Silent skip when worktree lookup fails.

```rust
// Line 47: No else clause — if find_worktree fails, this worktree is
// silently skipped and its branch may be wrongly reported as orphaned
if let Ok(worktree) = repo.find_worktree(worktree_name) {
    if let Ok(worktree_repo) = Repository::open(worktree.path())
        && let Ok(head) = worktree_repo.head()
        && let Some(branch_name) = head.shorthand()
    {
        active_branches.insert(branch_name.to_string());
    }
}
```

**`detect_orphaned_branches()` — line 59**: Silent skip when repo HEAD fails.

```rust
// Line 59: No else clause — if repo.head() fails, main branch may not
// be added to active_branches, causing false positives
if let Ok(head) = repo.head()
    && let Some(branch_name) = head.shorthand()
{
    active_branches.insert(branch_name.to_string());
}
```

**`detect_orphaned_worktrees()` — line 90**: Silent skip when worktree lookup fails.

```rust
// Line 90: No else clause — corrupted worktrees silently excluded from results
if let Ok(worktree) = repo.find_worktree(worktree_name) {
```

**Contrast with `detect_untracked_worktrees()` (line 159)** which already has proper error handling:

```rust
let worktree = match repo.find_worktree(worktree_name) {
    Ok(wt) => wt,
    Err(e) => {
        warn!(
            event = "core.cleanup.worktree_find_failed",
            worktree_name = %worktree_name,
            error = %e,
            "Could not access registered worktree - it may be corrupted or inaccessible"
        );
        continue;
    }
};
```

#### Minor: Scrollback read in `create.rs:312`

```rust
// Line 312: Scrollback read failure silently suppressed during early-exit diagnostic
crate::daemon::client::read_scrollback(&daemon_result.daemon_session_id)
    .ok()
    .flatten()
```

This is a diagnostic path (showing scrollback when agent exits early). Logging the failure would help debug daemon IPC issues.

### Issue #413: Orphaned UI daemon sessions

**Root cause**: UI-created daemon sessions use the naming pattern `{session_id}_ui_shell_{N}` (see `main_view.rs:809`) but are NOT tracked in the session file's `agents` array. `destroy_session()` only iterates `session.agents()` (line 164), so UI sessions are never cleaned up.

**Current destroy flow** (`destroy.rs:162-269`):
```
For each agent in session.agents():
  → destroy_daemon_session(daemon_sid) via IPC
```

**Missing cleanup**: After tracked agents are cleaned up, there's no sweep for untracked daemon sessions with the `{session_id}_` prefix.

**UI tab close**: Already handled correctly — `on_close_tab()` calls `stop_daemon_session_async()` which stops the daemon session via IPC (`main_view.rs:1639-1640`). The `Terminal::drop` sending `Detach` instead of `Destroy` is by design — it allows reconnection if the UI is accidentally closed.

**Solution**: Add a daemon client function to list all sessions, filter by prefix, and destroy orphaned ones during `kild destroy`. Since `complete_session()` delegates to `destroy_session()` (line 167), it gets this cleanup for free.

### Evidence Chain

WHY: UI-created daemon sessions (`{session_id}_ui_shell_N`) leak as orphaned PTYs
BECAUSE: `destroy_session()` only cleans up sessions in `session.agents()`
Evidence: `destroy.rs:164` — `for agent_proc in session.agents()`

BECAUSE: UI-created sessions are not tracked in the session file
Evidence: `main_view.rs:809` — `format!("{}_ui_shell_{}", kild_id, counter)` — created on-the-fly, never persisted

ROOT CAUSE: No daemon session sweep during destroy to catch untracked sessions
Evidence: No `ListSessions` IPC call in destroy path; daemon client has no `list_sessions` function

### Affected Files

| File                                              | Lines   | Action | Description                                       |
| ------------------------------------------------- | ------- | ------ | ------------------------------------------------- |
| `crates/kild-core/src/cleanup/operations.rs`      | 46-55   | UPDATE | Add warn logging for `detect_orphaned_branches`   |
| `crates/kild-core/src/cleanup/operations.rs`      | 59-62   | UPDATE | Add warn logging for main branch detection        |
| `crates/kild-core/src/cleanup/operations.rs`      | 89-118  | UPDATE | Add warn logging for `detect_orphaned_worktrees`  |
| `crates/kild-core/src/daemon/client.rs`           | NEW     | UPDATE | Add `list_daemon_sessions()` function             |
| `crates/kild-core/src/sessions/destroy.rs`        | 269     | UPDATE | Add UI daemon session sweep after agent cleanup   |
| `crates/kild-core/src/sessions/create.rs`         | 312     | UPDATE | Log scrollback read failure before `.ok()`        |

### Integration Points

- `complete.rs:167` calls `destroy_session()` — gets UI session cleanup for free
- `daemon/client.rs` uses `kild_protocol::ClientMessage::ListSessions` — protocol already exists
- `cleanup/operations.rs` functions are called from cleanup CLI commands

### Git History

- `6b33654` (latest) - refactor: Rust idiom micro-optimizations
- `33f1e8a` - fix: clean up orphaned kild/* branches on destroy
- `71f3343` - feat: add kild-tmux-shim for agent team support (introduced shim child PTY cleanup pattern)

---

## Implementation Plan

### Step 1: Add `list_daemon_sessions()` to daemon client

**File**: `crates/kild-core/src/daemon/client.rs`
**Action**: UPDATE — add new function after `read_scrollback()`

**Required change:**

```rust
/// List all daemon sessions, optionally filtered by session ID prefix.
///
/// Returns all sessions from the daemon. The caller can filter by prefix
/// to find sessions belonging to a specific kild (e.g., UI-created shells).
pub fn list_daemon_sessions() -> Result<Vec<kild_protocol::SessionInfo>, DaemonClientError> {
    let socket_path = crate::daemon::socket_path();

    debug!(event = "core.daemon.list_sessions_started");

    let request = ClientMessage::ListSessions {
        id: "list-sessions".to_string(),
        project_id: None,
    };

    let mut stream = connect(&socket_path)?;
    let response = send_request(&mut stream, &request)?;

    match response {
        DaemonMessage::SessionList { sessions, .. } => {
            debug!(
                event = "core.daemon.list_sessions_completed",
                count = sessions.len()
            );
            Ok(sessions)
        }
        _ => Err(DaemonClientError::ProtocolError {
            message: "Expected SessionList response".to_string(),
        }),
    }
}
```

**Why**: The daemon protocol already supports `ListSessions` but there's no client function to call it. This is needed to discover UI-created sessions during destroy.

---

### Step 2: Add UI daemon session sweep to `destroy_session()`

**File**: `crates/kild-core/src/sessions/destroy.rs`
**Lines**: After line 269 (after the tracked agent cleanup block, before shim cleanup)
**Action**: UPDATE

**Current code** (line 269):
```rust
    } // end of tracked agent kill block

    // 3b. Clean up tmux shim state and destroy child shim panes
```

**Required change** — insert between these sections:

```rust
    } // end of tracked agent kill block

    // 3a. Sweep for untracked daemon sessions (e.g., UI-created shells)
    //
    // UI-created daemon sessions use the naming pattern `{session_id}_ui_shell_{N}`
    // and are not tracked in the session file. Query the daemon for all sessions
    // with a matching prefix and destroy any remaining ones.
    {
        let prefix = format!("{}_ui_shell_", session.id);
        match crate::daemon::client::list_daemon_sessions() {
            Ok(sessions) => {
                let ui_sessions: Vec<_> = sessions
                    .iter()
                    .filter(|s| s.id.starts_with(&prefix))
                    .collect();

                if !ui_sessions.is_empty() {
                    info!(
                        event = "core.session.destroy_ui_sessions_sweep_started",
                        session_id = session.id,
                        count = ui_sessions.len()
                    );
                }

                for daemon_session in ui_sessions {
                    info!(
                        event = "core.session.destroy_ui_session",
                        daemon_session_id = daemon_session.id,
                    );
                    if let Err(e) =
                        crate::daemon::client::destroy_daemon_session(&daemon_session.id, true)
                    {
                        warn!(
                            event = "core.session.destroy_ui_session_failed",
                            daemon_session_id = daemon_session.id,
                            error = %e,
                        );
                        eprintln!(
                            "Warning: Failed to clean up UI terminal session {}: {}",
                            daemon_session.id, e
                        );
                    }
                }
            }
            Err(crate::daemon::client::DaemonClientError::NotRunning { .. }) => {
                // Daemon not running — no UI sessions to clean up
                debug!(
                    event = "core.session.destroy_ui_sessions_sweep_skipped",
                    session_id = session.id,
                    reason = "daemon_not_running"
                );
            }
            Err(e) => {
                warn!(
                    event = "core.session.destroy_ui_sessions_sweep_failed",
                    session_id = session.id,
                    error = %e,
                    "Could not query daemon for orphaned UI sessions"
                );
            }
        }
    }

    // 3b. Clean up tmux shim state and destroy child shim panes
```

**Why**: This catches all UI-created daemon sessions that weren't tracked in the session file. The `DaemonClientError::NotRunning` case is expected (daemon may not be running) and is handled gracefully.

---

### Step 3: Add warn logging to `detect_orphaned_branches()`

**File**: `crates/kild-core/src/cleanup/operations.rs`
**Lines**: 46-63
**Action**: UPDATE

**Current code:**
```rust
    for worktree_name in worktrees.iter().flatten() {
        if let Ok(worktree) = repo.find_worktree(worktree_name) {
            // Try to get the branch name from the worktree
            if let Ok(worktree_repo) = Repository::open(worktree.path())
                && let Ok(head) = worktree_repo.head()
                && let Some(branch_name) = head.shorthand()
            {
                active_branches.insert(branch_name.to_string());
            }
        }
    }

    // Also add the main branch (current HEAD of main repo)
    if let Ok(head) = repo.head()
        && let Some(branch_name) = head.shorthand()
    {
        active_branches.insert(branch_name.to_string());
    }
```

**Required change:**
```rust
    for worktree_name in worktrees.iter().flatten() {
        match repo.find_worktree(worktree_name) {
            Ok(worktree) => {
                // Try to get the branch name from the worktree
                if let Ok(worktree_repo) = Repository::open(worktree.path())
                    && let Ok(head) = worktree_repo.head()
                    && let Some(branch_name) = head.shorthand()
                {
                    active_branches.insert(branch_name.to_string());
                }
            }
            Err(e) => {
                warn!(
                    event = "core.cleanup.worktree_find_failed",
                    worktree_name = %worktree_name,
                    error = %e,
                    "Could not access registered worktree during branch scan — its branch may be falsely reported as orphaned"
                );
            }
        }
    }

    // Also add the main branch (current HEAD of main repo)
    match repo.head() {
        Ok(head) => {
            if let Some(branch_name) = head.shorthand() {
                active_branches.insert(branch_name.to_string());
            }
        }
        Err(e) => {
            warn!(
                event = "core.cleanup.repo_head_read_failed",
                error = %e,
                "Could not read repository HEAD — main branch may be falsely reported as orphaned"
            );
        }
    }
```

**Why**: Mirrors the error handling pattern already used in `detect_untracked_worktrees()` (line 159). Logs actionable messages explaining the consequence of the failure.

---

### Step 4: Add warn logging to `detect_orphaned_worktrees()`

**File**: `crates/kild-core/src/cleanup/operations.rs`
**Lines**: 89-119
**Action**: UPDATE

**Current code:**
```rust
    for worktree_name in worktrees.iter().flatten() {
        if let Ok(worktree) = repo.find_worktree(worktree_name) {
            let worktree_path = worktree.path();

            // Check if worktree directory exists but is in a bad state
            if worktree_path.exists() {
                // Try to open the worktree as a repository
                match Repository::open(worktree_path) {
                    Ok(worktree_repo) => {
                        // Check if HEAD is detached or in a bad state
                        if let Ok(head) = worktree_repo.head() {
```

**Required change:**
```rust
    for worktree_name in worktrees.iter().flatten() {
        let worktree = match repo.find_worktree(worktree_name) {
            Ok(wt) => wt,
            Err(e) => {
                warn!(
                    event = "core.cleanup.worktree_find_failed",
                    worktree_name = %worktree_name,
                    error = %e,
                    "Could not access registered worktree during orphan scan — skipping"
                );
                continue;
            }
        };
        let worktree_path = worktree.path();

        // Check if worktree directory exists but is in a bad state
        if worktree_path.exists() {
            // Try to open the worktree as a repository
            match Repository::open(worktree_path) {
                Ok(worktree_repo) => {
                    // Check if HEAD is detached or in a bad state
                    if let Ok(head) = worktree_repo.head() {
```

**Why**: Consistent with the pattern in `detect_untracked_worktrees()`. Uses `match` + `continue` instead of `if let Ok(...)` to surface the error.

---

### Step 5: Log scrollback read failure in `create.rs`

**File**: `crates/kild-core/src/sessions/create.rs`
**Lines**: 311-313
**Action**: UPDATE

**Current code:**
```rust
                let scrollback_tail =
                    crate::daemon::client::read_scrollback(&daemon_result.daemon_session_id)
                        .ok()
                        .flatten()
```

**Required change:**
```rust
                let scrollback_tail =
                    crate::daemon::client::read_scrollback(&daemon_result.daemon_session_id)
                        .inspect_err(|e| {
                            debug!(
                                event = "core.session.scrollback_read_failed",
                                daemon_session_id = daemon_result.daemon_session_id,
                                error = %e,
                            );
                        })
                        .ok()
                        .flatten()
```

**Why**: Uses `debug!` level (not `warn!`) because this is a diagnostic-only path — failure to read scrollback during early-exit reporting is non-critical. Follows the same `inspect_err` + `.ok()` pattern used in `info.rs:49-56`.

---

## Patterns to Follow

**From codebase — mirror these exactly:**

```rust
// SOURCE: cleanup/operations.rs:159-169
// Pattern for worktree find with error logging (in detect_untracked_worktrees)
let worktree = match repo.find_worktree(worktree_name) {
    Ok(wt) => wt,
    Err(e) => {
        warn!(
            event = "core.cleanup.worktree_find_failed",
            worktree_name = %worktree_name,
            error = %e,
            "Could not access registered worktree - it may be corrupted or inaccessible"
        );
        continue;
    }
};
```

```rust
// SOURCE: destroy.rs:293-306
// Pattern for daemon session destruction with error logging
if let Err(e) = crate::daemon::client::destroy_daemon_session(child_sid, true) {
    error!(
        event = "core.session.destroy_shim_child_failed",
        daemon_session_id = child_sid,
        error = %e,
    );
    eprintln!("Warning: Failed to destroy agent team PTY {}: {}", pane_id, e);
}
```

```rust
// SOURCE: info.rs:49-56
// Pattern for logging before .ok() via inspect_err
.inspect_err(|e| {
    warn!(
        event = "core.session.diff_stats_failed",
        path = %session.worktree_path.display(),
        error = %e,
        "Failed to compute diff stats"
    );
})
.ok()
```

---

## Edge Cases & Risks

| Risk/Edge Case                          | Mitigation                                                              |
| --------------------------------------- | ----------------------------------------------------------------------- |
| Daemon not running during destroy       | `DaemonClientError::NotRunning` handled gracefully, logged at debug     |
| ListSessions IPC timeout                | 30-second read timeout already set on socket; failure logged as warn    |
| Session ID prefix collision             | Use `{session_id}_ui_shell_` prefix (specific enough to avoid false matches) |
| Concurrent UI sessions being created    | Best-effort sweep — racing sessions may survive one destroy cycle       |
| `detect_orphaned_branches` false report | Logging the worktree find failure + message explains consequence        |

---

## Validation

### Automated Checks

```bash
cargo fmt --check
cargo clippy --all -- -D warnings
cargo test --all
cargo build --all
```

### Manual Verification

1. Create a daemon-managed kild, open extra terminal tabs in UI, then `kild destroy` from CLI — verify UI sessions are cleaned up
2. Run `kild cleanup` with verbose logging to verify git2 failures are now logged
3. Confirm no regressions in destroy/complete flows

---

## Scope Boundaries

**IN SCOPE:**
- Add warn logging to `if let Ok(...)` patterns in `cleanup/operations.rs`
- Add `list_daemon_sessions()` to daemon client
- Add UI daemon session sweep to `destroy_session()`
- Add `inspect_err` logging to scrollback read in `create.rs`

**OUT OF SCOPE (do not touch):**
- `Terminal::drop` Detach behavior (by design — allows reconnection)
- Config loading `.ok()` patterns (intentional fallback to auto-detection)
- "Daemon Sessions browser" UI mentioned in #413 (separate feature, not needed for cleanup)
- `store.rs:31` `.ok()` in filter_map (iterator pattern, not error discarding)

---

## Metadata

- **Investigated by**: Claude
- **Timestamp**: 2026-02-16T12:00:00Z
- **Artifact**: `.claude/PRPs/issues/issue-424-413.md`
